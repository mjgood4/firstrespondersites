{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import sqlite3\n",
    "\n",
    "from numpy import asarray\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBRFRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# hide warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connection(path):\n",
    "    connection = None \n",
    "    connection = sqlite3.connect(path)\n",
    "    connection.text_factory = str\n",
    "\n",
    "    return connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "    if query == \"\":\n",
    "        return \"Query Blank\"\n",
    "    else:\n",
    "        cursor.execute(query)\n",
    "        connection.commit()\n",
    "        return \"Query executed successfully\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_table(connection, tableName, columns):\n",
    "    sql = F\"DROP TABLE IF EXISTS {tableName}; \"\n",
    "    execute_query(connection, sql)\n",
    "    sql = F\"CREATE TABLE {tableName} ({columns}); \"\n",
    "    return execute_query(connection, sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def insert_into_table(connection, table_name, columns, records):\n",
    "    values = \"\"\n",
    "    for record in records:\n",
    "        record = record.replace(\"'\", \"\")\n",
    "        if len(values) > 0:\n",
    "            values+=\",\"\n",
    "        if str.isnumeric(record):\n",
    "            values+= str(record)\n",
    "        else:\n",
    "            values +=F\"'{record}'\"\n",
    "\n",
    "    sql= F\"INSERT INTO {table_name} ({columns}) VALUES ({values}); \"\n",
    "    return execute_query(connection, sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def is_successful( result):\n",
    "    return \"success\" in result\n",
    "    \n",
    "def import_file(connection, file, table_name, columns):\n",
    "\n",
    "    with open(file, encoding=\"utf8\") as file:\n",
    "\n",
    "        lines = csv.reader(file, delimiter=',')\n",
    "        for line in lines:\n",
    "                            \n",
    "            result = insert_into_table(connection, table_name, columns, line)\n",
    "            if not is_successful(result):\n",
    "                return result\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = create_connection('C:\\\\Data\\\\fire_data_v4.db\\\\fire_data_v4.db')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Query executed successfully'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_table(con, \"Truck_Engine_Fire_Station\", \"Station text, Type text, Unit text, FireStation text, Facility_ID text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Query executed successfully'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_file(con, \"C:\\\\repos\\\\gatech\\\\datavisualanalytics\\\\classproject\\\\firstrespondersites\\\\jyEDA\\\\clean\\\\truck_engine_fire_station.csv\", \"truck_engine_fire_station\", \"Station, Type, Unit, FireStation, Facility_ID\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(cpm):\n",
    "    cur = con.cursor()\n",
    "\n",
    "    df = pd.read_sql(\"select floating_catchment_output.[index] \" \\\n",
    "        \", floating_catchment_output.zone_idx \" \\\n",
    "        \", floating_catchment_output.accessibility_score \" \\\n",
    "        \", floating_catchment_output.scenario_name \" \\\n",
    "        \", calls_for_service.on_scene_dttm \" \\\n",
    "        \", calls_for_service.response_dttm   \" \\\n",
    "        \", fire_stations.facility_id \" \\\n",
    "        \", category_mappings.[index] as primary_situation_index \" \\\n",
    "        \", calls_for_service.case_location \" \\\n",
    "        \"from floating_catchment_output \" \\\n",
    "        \"inner join zone_idx_to_incident on  \" \\\n",
    "        \"zone_idx_to_incident.zone_idx = floating_catchment_output.zone_idx \" \\\n",
    "        \"inner join calls_for_service on calls_for_service.incident_number = zone_idx_to_incident.incident_number \" \\\n",
    "        \"left join fire_incidents AS fi on calls_for_service.incident_number = fi.incident_number \" \\\n",
    "        \"left join category_mappings on fi.primary_situation = category_mappings.primary_situation \" \\\n",
    "        \"left join Truck_Engine_Fire_Station on calls_for_service.unit_id = Truck_Engine_Fire_Station.Unit \" \\\n",
    "        \"left join fire_stations on fire_stations.facility_id = Truck_Engine_Fire_Station.Facility_ID \" \\\n",
    "        \"where calls_for_service.unit_type in ('TRUCK', 'ENGINE') \" \\\n",
    "        \"and scenario_name = 'baseline'\",con = con) \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data(con)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137437"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_columns(df):\n",
    "    df['on_scene_dttm'] = pd.to_datetime(df['on_scene_dttm'])\n",
    "    df['response_dttm'] = pd.to_datetime(df['response_dttm'])\n",
    "    df['arrival_time'] = (df['on_scene_dttm'] - df['response_dttm'])\n",
    "    df['minutes'] = (df.arrival_time.dt.seconds) / 60\n",
    "    df['seconds'] = (df.arrival_time.dt.seconds)\n",
    "    df['day_of_week'] = df['response_dttm'].dt.dayofweek\n",
    "    df['dayflag'] = (df.response_dttm.dt.hour > 5) & (df.response_dttm.dt.hour < 18)\n",
    "    \n",
    "    point = df['case_location'].str.split(' ', n = 2, expand = True)\n",
    "    point_x = point[1].str.split('(', n = 1, expand = True)\n",
    "    point_y = point[2].str.split(')', n = 1, expand = True)\n",
    "    \n",
    "    df['point_x'] = point_x[1]\n",
    "    df['point_y'] = point_y[0]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = format_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns(df):\n",
    "    cols = ['minutes','seconds','response_dttm','on_scene_dttm','day_of_week','dayflag',\\\n",
    "        'zone_idx', 'accessibility_score', 'facility_id', 'primary_situation_index', \\\n",
    "        'arrival_time', 'point_x', 'point_y']\n",
    "    \n",
    "    return df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    \n",
    "    df[\"facility_id\"] = pd.to_numeric(df[\"facility_id\"], errors='coerce')\n",
    "    df[\"primary_situation_index\"] = pd.to_numeric(df[\"primary_situation_index\"], errors='coerce')\n",
    "    \n",
    "    #Ignore NaN rows\n",
    "    df = df[df['minutes'].notna()]\n",
    "    df = df[df['point_x'].notna()]\n",
    "    df = df[df['point_y'].notna()]\n",
    "    df = df[df['facility_id'].notna()]\n",
    "    df = df[df['primary_situation_index'].notna()]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>minutes</th>\n",
       "      <th>seconds</th>\n",
       "      <th>response_dttm</th>\n",
       "      <th>on_scene_dttm</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>dayflag</th>\n",
       "      <th>zone_idx</th>\n",
       "      <th>accessibility_score</th>\n",
       "      <th>facility_id</th>\n",
       "      <th>primary_situation_index</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>point_x</th>\n",
       "      <th>point_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.750000</td>\n",
       "      <td>105.0</td>\n",
       "      <td>2019-01-06 00:52:49</td>\n",
       "      <td>2019-01-06 00:54:34</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>716.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0 days 00:01:45</td>\n",
       "      <td>-122.507197717067</td>\n",
       "      <td>37.779525347186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.116667</td>\n",
       "      <td>247.0</td>\n",
       "      <td>2019-01-06 00:53:23</td>\n",
       "      <td>2019-01-06 00:57:30</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>696.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0 days 00:04:07</td>\n",
       "      <td>-122.507197717067</td>\n",
       "      <td>37.779525347186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.816667</td>\n",
       "      <td>409.0</td>\n",
       "      <td>2019-01-14 12:25:54</td>\n",
       "      <td>2019-01-14 12:32:43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>700.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0 days 00:06:49</td>\n",
       "      <td>-122.513648358636</td>\n",
       "      <td>37.77848510937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.966667</td>\n",
       "      <td>178.0</td>\n",
       "      <td>2019-01-14 12:41:12</td>\n",
       "      <td>2019-01-14 12:44:10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>698.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0 days 00:02:58</td>\n",
       "      <td>-122.513648358636</td>\n",
       "      <td>37.77848510937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.800000</td>\n",
       "      <td>288.0</td>\n",
       "      <td>2019-01-14 12:24:23</td>\n",
       "      <td>2019-01-14 12:29:11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>706.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0 days 00:04:48</td>\n",
       "      <td>-122.513648358636</td>\n",
       "      <td>37.77848510937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     minutes  seconds       response_dttm       on_scene_dttm  day_of_week  \\\n",
       "4   1.750000    105.0 2019-01-06 00:52:49 2019-01-06 00:54:34          6.0   \n",
       "5   4.116667    247.0 2019-01-06 00:53:23 2019-01-06 00:57:30          6.0   \n",
       "7   6.816667    409.0 2019-01-14 12:25:54 2019-01-14 12:32:43          0.0   \n",
       "10  2.966667    178.0 2019-01-14 12:41:12 2019-01-14 12:44:10          0.0   \n",
       "11  4.800000    288.0 2019-01-14 12:24:23 2019-01-14 12:29:11          0.0   \n",
       "\n",
       "    dayflag  zone_idx  accessibility_score  facility_id  \\\n",
       "4     False         8             0.000803        716.0   \n",
       "5     False         8             0.000803        696.0   \n",
       "7      True         8             0.000803        700.0   \n",
       "10     True         8             0.000803        698.0   \n",
       "11     True         8             0.000803        706.0   \n",
       "\n",
       "    primary_situation_index    arrival_time            point_x  \\\n",
       "4                     148.0 0 days 00:01:45  -122.507197717067   \n",
       "5                     148.0 0 days 00:04:07  -122.507197717067   \n",
       "7                      81.0 0 days 00:06:49  -122.513648358636   \n",
       "10                     81.0 0 days 00:02:58  -122.513648358636   \n",
       "11                     81.0 0 days 00:04:48  -122.513648358636   \n",
       "\n",
       "            point_y  \n",
       "4   37.779525347186  \n",
       "5   37.779525347186  \n",
       "7    37.77848510937  \n",
       "10   37.77848510937  \n",
       "11   37.77848510937  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = select_columns(df)\n",
    "df = prepare_data(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_sets(md):\n",
    "    md.target_to_predict = 'minutes'\n",
    "    md.predictors = ['day_of_week','dayflag', 'zone_idx', 'accessibility_score', 'facility_id', 'primary_situation_index', 'point_x', 'point_y']\n",
    "    \n",
    "    md.x = df[md.predictors].values\n",
    "    md.y = df[md.target_to_predict].values\n",
    "\n",
    "    #Split the data into training and testing set\n",
    "    md.x_train, md.x_test, md.y_train, md.y_test = train_test_split(md.x, md.y, test_size=0.8, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(md):\n",
    "    #RegModel = XGBRegressor(max_depth=3, learning_rate=0.1, n_estimators=500, objective='reg:linear', booster='gbtree')\n",
    "    md.model = XGBRFRegressor(n_estimators=4000, subsample=0.9, colsample_bynode=0.2)\n",
    "\n",
    "    #Printing all the parameters of XGBoost\n",
    "    print(md.model)\n",
    "    \n",
    "    #Creating the model on Training Data\n",
    "    md.XGB = md.model.fit(md.x_train, md.y_train)\n",
    "    \n",
    "    prediction = md.XGB.predict(md.x_test)\n",
    "\n",
    "    #Measuring Goodness of fit in Training data\n",
    "    print('R2 Value:', metrics.r2_score(md.y_train, md.XGB.predict(md.x_train)))\n",
    "\n",
    "    #Measuring accuracy on Testing Data\n",
    "    print('Accuracy', 100 - (np.mean(np.abs((md.y_test - prediction) / md.y_test)) * 100))\n",
    "\n",
    "    #Plotting the feature importance for Top 10 most important columns \n",
    "    %matplotlib inline\n",
    "    feature_importances = pd.Series(md.XGB.feature_importances_, index = md.predictors)\n",
    "    feature_importances.nlargest(10).plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model(md):\n",
    "    # define the model evaluation procedure\n",
    "    cv = RepeatedKFold(n_splits = 10, n_repeats = 3, random_state = 1)\n",
    "    # evaluate the model and collect the scores\n",
    "    n_scores = cross_val_score(md.model, md.x, md.y, scoring = 'neg_mean_absolute_error', cv = cv, n_jobs = -1)\n",
    "    # report performance\n",
    "    print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_value(md):\n",
    "    row = [-122.429504, 37.783009]\n",
    "    row = asarray([row])\n",
    "    \n",
    "    prediction = md.model.predict(row)\n",
    "    \n",
    "    print('Prediction: %f' % prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_using_training_set(md):\n",
    "    prediction = md.XGB.predict(md.x_test)\n",
    "    \n",
    "    training_set_predictions = pd.DataFrame(data = md.x_test, columns = md.predictors)\n",
    "    training_set_predictions[md.target_to_predict] = md.y_test\n",
    "    training_set_predictions[('Predicted' + md.target_to_predict)] = prediction\n",
    "    training_set_predictions.head()\n",
    "    \n",
    "    print(training_set_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "configure_sets(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRFRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "               colsample_bynode=0.2, colsample_bytree=None,\n",
      "               enable_categorical=False, gamma=None, gpu_id=None,\n",
      "               importance_type=None, interaction_constraints=None,\n",
      "               max_delta_step=None, max_depth=None, min_child_weight=None,\n",
      "               missing=nan, monotone_constraints=None, n_estimators=4000,\n",
      "               n_jobs=None, num_parallel_tree=None,\n",
      "               objective='reg:squarederror', predictor=None, random_state=None,\n",
      "               reg_alpha=None, scale_pos_weight=None, subsample=0.9,\n",
      "               tree_method=None, validate_parameters=None, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "create_model(df)\n",
    "#cross_validate_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31139f53f3e7763be139e5f9ef1c49dd481e1a25247c7505f26cc1fc9191d362"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('jyEDA': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
